// useWebSpeech.ts
import { useCallback, useRef, useState, useEffect } from 'react';

interface WebSpeechResult {
  text: string;
  confidence: number;
  isFinal: boolean;
}

export const useWebSpeech = () => {
  const [transcript, setTranscript] = useState('');
  const [correctedText, setCorrectedText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isSupported, setIsSupported] = useState(false);
  const [confidence, setConfidence] = useState(0);
  
  const recognitionRef = useRef<any>(null);
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const finalTranscriptRef = useRef('');
  const interimTranscriptRef = useRef('');

  // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
  useEffect(() => {
    const SpeechRecognition = 
      (window as any).SpeechRecognition || 
      (window as any).webkitSpeechRecognition;
    setIsSupported(!!SpeechRecognition);
  }, []);

  // í…ìŠ¤íŠ¸ êµì • í•¨ìˆ˜
  const correctText = useCallback((text: string): string => {
    return text
      .replace(/ë°°ì˜¤ê³ /g, 'ë°°ìš°ê³ ')
      .replace(/ìžˆì„œìš”/g, 'ìžˆì–´ìš”')
      .replace(/ë¨¸ê±°ìš”/g, 'ë¨¹ì–´ìš”')
      .replace(/ê°€ë¥´í‚¤ë‹¤/g, 'ê°€ë¦¬í‚¤ë‹¤')
      .replace(/ë„ˆì™€ì„œ/g, 'ì–´ì„œì™€')
      .replace(/singles/g, 'ì‹±ê¸€ìŠ¤')
      .replace(/ì˜¤ëŠ˜/g, 'ì˜¤ëŠ˜')
      .replace(/ë‚ ì‹œ/g, 'ë‚ ì”¨')
      .replace(/ì•ˆë…•ížˆì„¸ìš”/g, 'ì•ˆë…•í•˜ì„¸ìš”');
  }, []);

  // ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
  useEffect(() => {
    const fullText = finalTranscriptRef.current + interimTranscriptRef.current;
    setTranscript(fullText);
    setCorrectedText(correctText(fullText));
  }, [correctText]);

  // ìŒì„± ì¸ì‹ ì‹œìž‘
  const startRecording = useCallback(() => {
    if (!isSupported) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const SpeechRecognition = 
      (window as any).SpeechRecognition || 
      (window as any).webkitSpeechRecognition;
    
    const recognition = new SpeechRecognition();
    
    // ì„¤ì •
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'ko-KR';
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      setIsListening(true);
      console.log('ðŸŽ¤ ìŒì„± ì¸ì‹ ì‹œìž‘');
    };

    recognition.onresult = (event: any) => {
      let interim = '';
      let final = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcriptText = event.results[i][0].transcript;
        const confidence = event.results[i][0].confidence;
        
        if (event.results[i].isFinal) {
          final += transcriptText;
          setConfidence(confidence || 0.9);
          console.log('âœ… ìµœì¢… ê²°ê³¼:', transcriptText);
        } else {
          interim += transcriptText;
        }
      }
      
      interimTranscriptRef.current = interim;
      
      if (final) {
        finalTranscriptRef.current += final + ' ';
        
        // ì¹¨ë¬µ ê°ì§€ íƒ€ì´ë¨¸ ë¦¬ì…‹
        if (silenceTimeoutRef.current) {
          clearTimeout(silenceTimeoutRef.current);
        }
        
        // 3ì´ˆ ì¹¨ë¬µ í›„ ìžë™ ì •ì§€
        silenceTimeoutRef.current = setTimeout(() => {
          stopRecording();
        }, 3000);
      }
      
      // ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
      const fullText = finalTranscriptRef.current + interim;
      setTranscript(fullText);
      setCorrectedText(correctText(fullText));
    };

    recognition.onerror = (event: any) => {
      console.error('âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      if (event.error === 'no-speech') {
        console.log('ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ');
      }
    };

    recognition.onend = () => {
      setIsListening(false);
      interimTranscriptRef.current = '';
      console.log('ðŸ”‡ ìŒì„± ì¸ì‹ ì¢…ë£Œ');
      
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current);
      }
    };

    recognitionRef.current = recognition;
    recognition.start();
  }, [isSupported, correctText]);

  // ìŒì„± ì¸ì‹ ì •ì§€
  const stopRecording = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
    
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
    }
    
    setIsListening(false);
    interimTranscriptRef.current = '';
  }, []);

  // ì´ˆê¸°í™”
  const resetTranscript = useCallback(() => {
    setTranscript('');
    setCorrectedText('');
    setConfidence(0);
    finalTranscriptRef.current = '';
    interimTranscriptRef.current = '';
  }, []);

  // TTS ìž¬ìƒ
  const speakText = useCallback((text: string) => {
    if ('speechSynthesis' in window && text) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ko-KR';
      utterance.rate = 0.9;
      speechSynthesis.speak(utterance);
    }
  }, []);

  // ì •í™•ë„ ê³„ì‚°
  const getAccuracy = useCallback(() => {
    if (!confidence) return 0;
    return Math.round(confidence * 100);
  }, [confidence]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopRecording();
    };
  }, [stopRecording]);

  return {
    transcript,
    correctedText,
    isListening,
    isSupported,
    confidence: getAccuracy(),
    startRecording,
    stopRecording,
    resetTranscript,
    speakText
  };
};