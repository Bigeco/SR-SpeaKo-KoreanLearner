import { ArrowLeft, Plus } from 'lucide-react';
import React, { useEffect, useRef, useState } from 'react';
import { useNavigate } from 'react-router-dom';
import { AudioRecorder } from '../../components/common/AudioRecorder';
import RecordControls from '../../components/common/RecordControls';
import { NavBar } from '../../components/layout/NavBar';
import { ScoreDisplay } from './components/ScoreDisplay';
import { SproutScore } from './components/SproutScore';
import TranscriptionCard from './components/TranscriptionCard';
import './styles/start-record.css';

// Web Speech API íƒ€ì… ì •ì˜
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onerror: ((this: SpeechRecognition, ev: Event) => any) | null;
}

declare global {
  interface Window {
    SpeechRecognition: {
      new (): SpeechRecognition;
    };
    webkitSpeechRecognition: {
      new (): SpeechRecognition;
    };
  }
}

const StartRecordView: React.FC = () => {
  const navigate = useNavigate();
  
  // ìƒíƒœ ê´€ë¦¬
  const [recordingState, setRecordingState] = useState<'idle' | 'recording' | 'completed'>('idle');
  const [isPlaying, setIsPlaying] = useState(false);
  const [showHelp, setShowHelp] = useState(false);
  
  // ì „ì‚¬ ë° êµì • í…ìŠ¤íŠ¸
  const [transcribedText, setTranscribedText] = useState<string>('');
  const [correctedText, setCorrectedText] = useState<string>('');
  const [interimText, setInterimText] = useState<string>(''); // ì¤‘ê°„ ê²°ê³¼ìš©
  
  // ëˆ„ì ëœ ìµœì¢… í…ìŠ¤íŠ¸ ê´€ë¦¬ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ìƒíƒœ
  const [accumulatedFinalText, setAccumulatedFinalText] = useState<string>('');
  
  // accumulatedFinalTextë¥¼ refë¡œë„ ì¶”ì í•˜ì—¬ ì‹¤ì‹œê°„ ìƒíƒœ í™•ì¸
  const accumulatedFinalTextRef = useRef('');
  useEffect(() => { accumulatedFinalTextRef.current = accumulatedFinalText; }, [accumulatedFinalText]);
  
  // ë°œìŒ ì •í™•ë„ - ë…¹ìŒ ì™„ë£Œ ì‹œì—ë§Œ ì„¤ì •
  const [accuracy, setAccuracy] = useState<number | null>(null);
  
  // í‹€ë¦° ìŒì†Œë“¤ (ì‹¤ì œë¡œëŠ” AI ë¶„ì„ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¬ ë°ì´í„°)
  const [incorrectPhonemes, setIncorrectPhonemes] = useState<string[]>([]);
  
  // Web Speech API ê´€ë ¨
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const [isSupported, setIsSupported] = useState<boolean>(false);
  const [micPermission, setMicPermission] = useState<'prompt' | 'granted' | 'denied'>('prompt');
  
  // ì˜¤ë””ì˜¤ ìš”ì†Œ ì°¸ì¡°
  const audioRef = useRef<HTMLAudioElement | null>(null);
  
  // recordingStateë¥¼ refë¡œ ì¶”ì 
  const recordingStateRef = useRef(recordingState);
  useEffect(() => { recordingStateRef.current = recordingState; }, [recordingState]);
  
  // Web Speech API ì§€ì› í™•ì¸ ë° ê¶Œí•œ ìš”ì²­
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      setIsSupported(true);
      recognitionRef.current = new SpeechRecognition();
      setupSpeechRecognition();
      
      // ë§ˆì´í¬ ê¶Œí•œ ë¯¸ë¦¬ í™•ì¸
      checkMicrophonePermission();
    } else {
      setIsSupported(false);
      console.warn('Web Speech APIê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
    }
  }, []);
  
  // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
  const checkMicrophonePermission = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop()); // ìŠ¤íŠ¸ë¦¼ ì¦‰ì‹œ ì •ì§€
      setMicPermission('granted');
    } catch (error) {
      console.log('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆê±°ë‚˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      setMicPermission('denied');
    }
  };
  
  // Speech Recognition ì„¤ì •
  const setupSpeechRecognition = () => {
    if (!recognitionRef.current) return;
    
    const recognition = recognitionRef.current;
    
    // ê¸°ë³¸ ì„¤ì •
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'ko-KR'; // í•œêµ­ì–´ ì„¤ì •
    
    // ìŒì„± ì¸ì‹ ì‹œì‘
    recognition.onstart = () => {
      console.log('ìŒì„± ì¸ì‹ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
    };
    
    // ìŒì„± ì¸ì‹ ê²°ê³¼
    recognition.onresult = (event: SpeechRecognitionEvent) => {
      // ë…¹ìŒì´ ì¤‘ì§€ëœ ìƒíƒœë©´ ê²°ê³¼ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
      if (recordingStateRef.current !== 'recording') {
        console.log('ë…¹ìŒ ì¤‘ì§€ ìƒíƒœì´ë¯€ë¡œ ìŒì„± ì¸ì‹ ê²°ê³¼ ë¬´ì‹œ');
        return;
      }
      
      let finalTranscript = '';
      let interimTranscript = '';
      
      console.log('Web Speech API ê²°ê³¼ ë°›ìŒ:', event.results.length);
      
      // ëª¨ë“  ê²°ê³¼ ì²˜ë¦¬
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        console.log(`ê²°ê³¼ ${i}: "${transcript}", isFinal: ${event.results[i].isFinal}`);
        
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }
      
      // ìµœì¢… ê²°ê³¼ê°€ ìˆì„ ë•Œ ëˆ„ì  (ë…¹ìŒ ì¤‘ì¼ ë•Œë§Œ)
      if (finalTranscript && recordingStateRef.current === 'recording') {
        console.log('ìµœì¢… ì¸ì‹ í…ìŠ¤íŠ¸:', `"${finalTranscript}"`);
        
        // ê¸°ì¡´ ëˆ„ì  í…ìŠ¤íŠ¸ì— ìƒˆë¡œìš´ ìµœì¢… í…ìŠ¤íŠ¸ ì¶”ê°€
        setAccumulatedFinalText(prev => {
          const newAccumulated = prev ? `${prev} ${finalTranscript}`.trim() : finalTranscript;
          console.log('ëˆ„ì ëœ ìµœì¢… í…ìŠ¤íŠ¸:', `"${newAccumulated}"`);
          return newAccumulated;
        });
        
        // ê³ ì •ëœ êµì • í…ìŠ¤íŠ¸ ì‚¬ìš©
        setCorrectedText(getFixedCorrectedText());
      }
      
      // ì¤‘ê°„ ê²°ê³¼ ì—…ë°ì´íŠ¸ (ì‹¤ì‹œê°„ í‘œì‹œìš©, ë…¹ìŒ ì¤‘ì¼ ë•Œë§Œ)
      if (interimTranscript && recordingStateRef.current === 'recording') {
        console.log('ì¤‘ê°„ ê²°ê³¼ ì—…ë°ì´íŠ¸:', `"${interimTranscript}"`);
        setInterimText(interimTranscript);
      }
    };
    
    // ìŒì„± ì¸ì‹ ì¢…ë£Œ
    recognition.onend = () => {
      console.log('ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
      if (recordingStateRef.current === 'recording') {
        // ìë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘ (continuousë¥¼ ìœ„í•´)
        try {
          recognition.start();
        } catch (error) {
          console.log('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜:', error);
        }
      }
    };
    
    // ì˜¤ë¥˜ ì²˜ë¦¬
    recognition.onerror = (event: any) => {
      console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      if (event.error === 'not-allowed') {
        alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    };
  };
  
  // í…ŒìŠ¤íŠ¸ìš© ê³ ì • êµì • ë¬¸ì¥
  const getFixedCorrectedText = (): string => {
    // ì—¬ê¸°ì— ì›í•˜ëŠ” êµì • ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” (ë§ˆì¹¨í‘œ ì œê±°)
    return "ìˆ˜í•™ì„ ë°°ìš°ê³  ìˆì–´ìš”";
  };
  
  // í˜ì´ì§€ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  const handleGoBack = () => navigate(-1);
  
  // êµ¬ê°• êµ¬ì¡° í˜ì´ì§€ë¡œ ì´ë™
  const handleOralStructureView = () => {
    navigate('/oral-structure', {
      state: {
        incorrectPhonemes: incorrectPhonemes.length > 0 ? incorrectPhonemes : ['ã„±', 'ã…“', 'ã„¹'] // ì˜ˆì‹œ ë°ì´í„°
      }
    });
  };
  
  // í…ìŠ¤íŠ¸ ì •ê·œí™” í•¨ìˆ˜ (êµ¬ë‘ì  ì œê±° ë° ê³µë°± ì •ë¦¬)
  const normalizeText = (text: string): string => {
    return text
      .replace(/[.,!?;:]/g, '') // êµ¬ë‘ì  ì œê±°
      .replace(/\s+/g, ' ')     // ì—°ì† ê³µë°±ì„ í•˜ë‚˜ë¡œ
      .trim();                  // ì•ë’¤ ê³µë°± ì œê±° (toLowerCase ì œê±°)
  };
  
  // ë°œìŒ ì •í™•ë„ ê³„ì‚°
  const calculateAccuracy = (original: string, corrected: string): number => {
    console.log('=== ì •í™•ë„ ê³„ì‚° ì‹œì‘ ===');
    console.log('ì›ë³¸ ì…ë ¥:', { 
      original: `"${original}"`, 
      corrected: `"${corrected}"`,
      originalType: typeof original,
      correctedType: typeof corrected
    });
    
    // null, undefined, ë¹ˆ ë¬¸ìì—´ ì²´í¬
    if (!original || !corrected || original.trim() === '' || corrected.trim() === '') {
      console.log('âŒ ë¹ˆ í…ìŠ¤íŠ¸ ë˜ëŠ” null/undefinedë¡œ ì¸í•œ 0% ë°˜í™˜');
      return 0;
    }
    
    // í…ìŠ¤íŠ¸ ì •ê·œí™”
    const normalizedOriginal = normalizeText(original);
    const normalizedCorrected = normalizeText(corrected);
    
    console.log('ì •ê·œí™” í›„:', { 
      normalizedOriginal: `"${normalizedOriginal}"`, 
      normalizedCorrected: `"${normalizedCorrected}"`
    });
    
    // ì •ê·œí™” í›„ ë¹ˆ ë¬¸ìì—´ ì²´í¬
    if (!normalizedOriginal || !normalizedCorrected || 
        normalizedOriginal.trim() === '' || normalizedCorrected.trim() === '') {
      console.log('âŒ ì •ê·œí™” í›„ ë¹ˆ í…ìŠ¤íŠ¸ë¡œ ì¸í•œ 0% ë°˜í™˜');
      return 0;
    }
    
    // ì™„ì „íˆ ë™ì¼í•œ ê²½ìš°ë§Œ 100%
    if (normalizedOriginal === normalizedCorrected) {
      console.log('âœ… ì™„ì „íˆ ë™ì¼í•œ í…ìŠ¤íŠ¸ â†’ 100% ë°˜í™˜');
      return 100.0;
    }
    
    // ë‹¨ì–´ ë¶„ë¦¬
    const originalWords = normalizedOriginal.split(/\s+/).filter(word => word.length > 0);
    const correctedWords = normalizedCorrected.split(/\s+/).filter(word => word.length > 0);
    
    console.log('ë‹¨ì–´ ë¶„ë¦¬ í›„:', { 
      originalWords, 
      correctedWords,
      originalLength: originalWords.length,
      correctedLength: correctedWords.length
    });
    
    const maxLength = Math.max(originalWords.length, correctedWords.length);
    
    if (maxLength === 0) {
      console.log('âŒ ë‹¨ì–´ê°€ ì—†ì–´ì„œ 0% ë°˜í™˜');
      return 0;
    }
    
    let matchCount = 0;
    const minLength = Math.min(originalWords.length, correctedWords.length);
    
    // ë‹¨ì–´ë³„ ë¹„êµ
    for (let i = 0; i < minLength; i++) {
      console.log(`ë‹¨ì–´ ${i}: "${originalWords[i]}" vs "${correctedWords[i]}"`);
      if (originalWords[i] === correctedWords[i]) {
        matchCount++;
        console.log(`  âœ… ì¼ì¹˜`);
      } else {
        console.log(`  âŒ ë¶ˆì¼ì¹˜`);
      }
    }
    
    // ê¸¸ì´ê°€ ë‹¤ë¥¸ ê²½ìš° - ì¶”ê°€ ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ë¶ˆì¼ì¹˜ë¡œ ì²˜ë¦¬
    if (originalWords.length !== correctedWords.length) {
      console.log(`âš ï¸ ë‹¨ì–´ ê°œìˆ˜ ì°¨ì´: ${originalWords.length} vs ${correctedWords.length}`);
    }
    
    // ì •í™•ë„ ê³„ì‚°: ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ ìˆ˜ / ë” ê¸´ ë¬¸ì¥ì˜ ë‹¨ì–´ ìˆ˜
    const accuracyValue = (matchCount / maxLength) * 100;
    
    console.log('ğŸ“Š ìµœì¢… ê³„ì‚°:', { 
      matchCount: `${matchCount}ê°œ ì¼ì¹˜`, 
      maxLength: `ì´ ${maxLength}ê°œ ë‹¨ì–´`, 
      calculation: `${matchCount} / ${maxLength} * 100`,
      accuracyValue: `${accuracyValue}%`
    });
    
    // ê²€ì¦: ì™„ì „íˆ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë©´ 0%ê°€ ë˜ì–´ì•¼ í•¨
    if (matchCount === 0) {
      console.log('ğŸ” ê²€ì¦: ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ê°€ ì—†ìœ¼ë¯€ë¡œ 0%');
    }
    
    console.log('=== ì •í™•ë„ ê³„ì‚° ì™„ë£Œ ===');
    
    // ì†Œìˆ˜ì  í•œ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
    const result = Math.round(accuracyValue * 10) / 10;
    console.log(`ğŸ¯ ìµœì¢… ë°˜í™˜ê°’: ${result}%`);
    
    return result;
  };
  
  // í‹€ë¦° ìŒì†Œ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜ - ì‹¤ì œë¡œëŠ” AIê°€ ë¶„ì„)
  const analyzeIncorrectPhonemes = (original: string, corrected: string): string[] => {
    const incorrectPhonemes: string[] = [];
    
    // ê°„ë‹¨í•œ ë‹¨ì–´ë³„ ë¹„êµ
    const originalWords = original.split(' ');
    const correctedWords = corrected.split(' ');
    
    for (let i = 0; i < originalWords.length; i++) {
      if (originalWords[i] !== correctedWords[i]) {
        // ì˜ˆì‹œ: 'ë°°ì˜¤ê³ ' vs 'ë°°ìš°ê³ ' -> 'ã…—' vs 'ã…œ' ì°¨ì´
        if (originalWords[i]?.includes('ë°°ì˜¤ê³ ') && correctedWords[i]?.includes('ë°°ìš°ê³ ')) {
          incorrectPhonemes.push('ã…—', 'ã…œ');
        }
        // ì˜ˆì‹œ: 'ìˆì„œìš”' vs 'ìˆì–´ìš”' -> 'ã……' vs 'ã…‡' ì°¨ì´  
        if (originalWords[i]?.includes('ìˆì„œìš”') && correctedWords[i]?.includes('ìˆì–´ìš”')) {
          incorrectPhonemes.push('ã……', 'ã…‡');
        }
      }
    }
    
    // ì¤‘ë³µ ì œê±° ë° ê¸°ë³¸ê°’
    const uniquePhonemes = [...new Set(incorrectPhonemes)];
    return uniquePhonemes.length > 0 ? uniquePhonemes : ['ã„±', 'ã…“', 'ã„¹'];
  };
  
  // ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ ì²˜ë¦¬
  const handleRecordingToggle = async (isRecording: boolean) => {
    if (!isSupported) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome, Safari, Edgeë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
      return;
    }
    
    if (isRecording) {
      // ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ëœ ê²½ìš° ë‹¤ì‹œ ìš”ì²­
      if (micPermission === 'denied') {
        await checkMicrophonePermission();
        if (micPermission === 'denied') {
          alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
          return;
        }
      }
      
      // ë…¹ìŒ ì‹œì‘ - ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”
      setRecordingState('recording');
      setTranscribedText('');
      setAccumulatedFinalText(''); // ëˆ„ì  í…ìŠ¤íŠ¸ë„ ì´ˆê¸°í™”
      setCorrectedText('');
      setInterimText('');
      setAccuracy(null);
      setIncorrectPhonemes([]);
      
      // Web Speech API ì‹œì‘
      try {
        recognitionRef.current?.start();
      } catch (error) {
        console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', error);
      }
    } else {
      // ë…¹ìŒ ì¤‘ì§€
      console.log('ë…¹ìŒ ì¤‘ì§€ ì‹œì‘ - ìƒíƒœ ë³€ê²½');
      setRecordingState('completed'); // ë¨¼ì € ìƒíƒœ ë³€ê²½í•˜ì—¬ ì¶”ê°€ onresult ì´ë²¤íŠ¸ ì°¨ë‹¨
      
      recognitionRef.current?.stop();
      
      // ë” ê¸´ ì§€ì—°ìœ¼ë¡œ Web Speech API ìµœì¢… ê²°ê³¼ ëŒ€ê¸°
      setTimeout(() => {
        // refì—ì„œ ìµœì‹  ìƒíƒœ í™•ì¸ (í´ë¡œì € ë¬¸ì œ ë°©ì§€)
        const currentAccumulatedText = accumulatedFinalTextRef.current;
        const currentInterimText = interimText;
        
        console.log('ë…¹ìŒ ì¤‘ì§€ í›„ ìµœì‹  ìƒíƒœ í™•ì¸:', { 
          currentAccumulatedText: `"${currentAccumulatedText}"`,
          currentInterimText: `"${currentInterimText}"`
        });
        
        // ì‹¤ì œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì¤‘ê°„ í…ìŠ¤íŠ¸ë¼ë„ ì‚¬ìš©
        let finalText = currentAccumulatedText;
        if (!finalText && currentInterimText) {
          console.log('ìµœì¢… í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ì¤‘ê°„ í…ìŠ¤íŠ¸ ì‚¬ìš©:', currentInterimText);
          finalText = currentInterimText;
        }
        if (!finalText) {
          console.log('ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ìš© fallback ì‚¬ìš©');
          finalText = "ìˆ˜í•™ì„ ë°°ì˜¤ê³  ìˆì–´ìš”"; // í…ŒìŠ¤íŠ¸ìš© fallback
        }
        
        const correctionText = getFixedCorrectedText();
        
        console.log('ë…¹ìŒ ì¤‘ì§€ - ìµœì¢… ì²˜ë¦¬:', { 
          stateAccumulatedText: `"${accumulatedFinalText}"`,
          refAccumulatedText: `"${currentAccumulatedText}"`,
          finalText: `"${finalText}"`
        });
        
        // UIì— ìµœì¢… í…ìŠ¤íŠ¸ í‘œì‹œ
        setTranscribedText(finalText);
        setCorrectedText(correctionText);
        
        // ì •í™•ë„ ê³„ì‚° ë° ìƒíƒœ ì—…ë°ì´íŠ¸
        const finalAccuracy = calculateAccuracy(finalText, correctionText);
        setAccuracy(finalAccuracy);
        setIncorrectPhonemes(analyzeIncorrectPhonemes(finalText, correctionText));
        // recordingStateëŠ” ì´ë¯¸ 'completed'ë¡œ ì„¤ì •ë¨
        setInterimText(''); // ì¤‘ê°„ í…ìŠ¤íŠ¸ ì œê±°
      }, 1000); // 1ì´ˆë¡œ ì§€ì—° ì‹œê°„ ì¦ê°€
    }
  };
  
  // ì˜¤ë””ì˜¤ ì¬ìƒ í† ê¸€ (ì‹¤ì œë¡œëŠ” ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì¬ìƒ)
  const togglePlayback = () => {
    setIsPlaying(!isPlaying);
    
    // ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•´ 3ì´ˆ í›„ ì¬ìƒ ìƒíƒœ í•´ì œ
    if (!isPlaying) {
      setTimeout(() => setIsPlaying(false), 3000);
    }
  };
  
  // ì „ì‚¬ ê²°ê³¼ì—ì„œ êµì •ëœ ë¶€ë¶„ í•˜ì´ë¼ì´íŠ¸
  const renderHighlightedCorrections = () => {
    const originalText = transcribedText;
    const correctionText = correctedText || getFixedCorrectedText();
    
    if (!originalText || !correctionText) return null;
    
    const transcribedWords = originalText.trim().split(/\s+/);
    const correctedWords = correctionText.trim().split(/\s+/);
    
    return (
      <div className="mt-3 pt-3 border-t border-green-100">
        <p className="text-sm text-gray-600">êµì •ëœ ë¶€ë¶„:</p>
        <div className="mt-1 text-sm">
          {transcribedWords.map((word, idx) => {
            const correctedWord = correctedWords[idx];
            const isChanged = word !== correctedWord;
            
            return (
              <span key={idx} className="inline-block mr-2">
                <span className={isChanged ? 'line-through text-red-500' : ''}>
                  {word}
                </span>
                {isChanged && correctedWord && (
                  <span className="inline-block ml-1 text-green-500">
                    â†’ {correctedWord}
                  </span>
                )}
              </span>
            );
          })}
        </div>
      </div>
    );
  };

  // í˜„ì¬ í‘œì‹œí•  í…ìŠ¤íŠ¸ (ë…¹ìŒ ì¤‘: ëˆ„ì ëœ ìµœì¢… í…ìŠ¤íŠ¸ + ì¤‘ê°„ í…ìŠ¤íŠ¸, ì™„ë£Œ: ìµœì¢… í…ìŠ¤íŠ¸)
  const getCurrentDisplayText = () => {
    if (recordingState === 'recording') {
      // ë…¹ìŒ ì¤‘ì¼ ë•Œ: ëˆ„ì ëœ ìµœì¢… í…ìŠ¤íŠ¸ + í˜„ì¬ ì¤‘ê°„ í…ìŠ¤íŠ¸
      const baseText = accumulatedFinalText;
      const currentText = interimText;
      return baseText && currentText ? `${baseText} ${currentText}` : (baseText || currentText);
    }
    // ì™„ë£Œ ìƒíƒœì¼ ë•Œ: transcribedText ì‚¬ìš©
    return transcribedText;
  };

  // Add toggleHelp handler
  const toggleHelp = () => setShowHelp((prev) => !prev);

  return (
    <div className="start-record-container">
      {/* í—¤ë” */}
      <div className="flex justify-between items-center p-6 border-b border-gray-100">
        <button 
          onClick={handleGoBack}
          className="p-1 rounded-full hover:bg-gray-100"
        >
          <ArrowLeft size={20} />
        </button>
        <div className="text-center font-medium">ë°œìŒ í™•ì¸</div>
        <div className="w-5"></div>
      </div>

      {/* Web Speech API ì§€ì› í™•ì¸ ì•Œë¦¼ */}
      {!isSupported && (
        <div className="bg-yellow-50 border-l-4 border-yellow-400 p-4 m-4">
          <div className="flex">
            <div className="ml-3">
              <p className="text-sm text-yellow-700">
                ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
                Chrome, Safari, Edge ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
              </p>
            </div>
          </div>
        </div>
      )}

      {/* ë©”ì¸ ì½˜í…ì¸  - í•˜ë‹¨ ìš”ì†Œë“¤ ê³µê°„ í™•ë³´ë¥¼ ìœ„í•œ íŒ¨ë”© ì¶”ê°€ */}
      <div className="flex-1 flex flex-col items-center px-6 py-4 overflow-auto pb-44">
        <div className="w-full max-w-md">
          {/* ìƒˆì‹¹ ìºë¦­í„° UI */}
          <div className="flex flex-col items-center mb-6 mt-9">
            <div className={`transition-all duration-500 
              ${recordingState === 'recording' ? 'opacity-60 grayscale' : 'opacity-100 grayscale-0'}`}>
              <SproutScore score={accuracy ?? 0} size={120} />
            </div>
          </div>  

          {/* ì•ˆë‚´ í…ìŠ¤íŠ¸ ë° ì •í™•ë„ í‘œì‹œ */}
          <div className="text-center mb-6">
            <h2 className="text-xl font-bold text-blue-600 mb-2">
              {recordingState === 'idle' && 'ë‹¹ì‹ ì˜ ë°œìŒì„ í™•ì¸í•´ ë³´ì„¸ìš”'}
              {recordingState === 'recording' && 'ë§í•˜ëŠ” ì¤‘...'}
              {recordingState === 'completed' && 'ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤'}
            </h2>
            <p className="text-gray-600 mb-2">
              {recordingState === 'idle' && 'ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ììœ ë¡­ê²Œ ë§í•´ë³´ì„¸ìš”.'}
              {recordingState === 'recording' && 'ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤.'}
              {recordingState === 'completed' && 'ì¸ì‹ëœ ë¬¸ì¥ê³¼ êµì •ëœ ë¬¸ì¥ì„ í™•ì¸í•˜ì„¸ìš”.'}
            </p>
            {/* ì •í™•ë„ ìˆ˜ì¹˜ì™€ í”¼ë“œë°± ë©”ì‹œì§€ */}
            {recordingState === 'completed' && accuracy !== null && (
              <ScoreDisplay score={accuracy} />
            )}
          </div>

          {/* ì „ì‚¬ ê²°ê³¼ ì¹´ë“œ */}
          <TranscriptionCard
            recordingState={recordingState}
            transcribedText={getCurrentDisplayText()}
            correctedText={correctedText}
            isPlaying={isPlaying}
            onPlayAudio={togglePlayback}
            renderHighlightedCorrections={renderHighlightedCorrections}
          />
          
          {/* ì¶”ê°€ ì•ˆë‚´ (idle ìƒíƒœì¼ ë•Œ) */}
          {recordingState === 'idle' && (
            <div className="bg-blue-50 rounded-lg p-4 text-center text-sm text-blue-700">
              <p>ìì—°ìŠ¤ëŸ½ê²Œ í•œêµ­ì–´ë¡œ ë§í•´ë³´ì„¸ìš”. ë°œìŒì´ ìë™ìœ¼ë¡œ êµì •ë©ë‹ˆë‹¤.</p>
              <p className="mt-2">ì˜ˆì‹œ: "ì•ˆë…•í•˜ì„¸ìš”", "ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”", "í•œêµ­ì–´ ê³µë¶€ê°€ ì¬ë¯¸ìˆì–´ìš”" ë“±</p>
              {!isSupported && (
                <p className="mt-2 text-red-600">
                  âš ï¸ í˜„ì¬ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                </p>
              )}
            </div>
          )}
          
          {/* ë¶„ì„ëœ í‹€ë¦° ìŒì†Œ ë¯¸ë¦¬ë³´ê¸° (completed ìƒíƒœì¼ ë•Œë§Œ) */}
          {recordingState === 'completed' && incorrectPhonemes.length > 0 && (
            <div className="bg-orange-50 rounded-lg p-4 mt-4">
              <h3 className="text-sm font-semibold text-orange-700 mb-2">ê°œì„ ì´ í•„ìš”í•œ ë°œìŒ</h3>
              <div className="flex flex-wrap gap-2 mb-3">
                {incorrectPhonemes.map((phoneme, index) => (
                  <span 
                    key={index}
                    className="inline-block bg-orange-200 text-orange-800 px-2 py-1 rounded text-sm font-medium"
                  >
                    {phoneme}
                  </span>
                ))}
              </div>
              <p className="text-orange-600 text-xs">
                êµ¬ê°• êµ¬ì¡° í•™ìŠµì„ í†µí•´ ì •í™•í•œ ë°œìŒë²•ì„ ìµí˜€ë³´ì„¸ìš”!
              </p>
            </div>
          )}
          
          {/* ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ ìš”ì†Œ */}
          <audio ref={audioRef} className="hidden" />
        </div>
      </div>

      {/* êµ¬ê°• êµ¬ì¡° í•™ìŠµ ë²„íŠ¼ - completed ìƒíƒœì¼ ë•Œë§Œ í‘œì‹œ */}
      {recordingState === 'completed' && (
        <button
          onClick={handleOralStructureView}
          className="fixed bottom-44 right-6 w-12 h-12 bg-orange-500 text-white rounded-full flex items-center justify-center shadow-lg hover:bg-orange-600 transition-all duration-200 hover:scale-110 z-20"
          title="êµ¬ê°• êµ¬ì¡° í•™ìŠµí•˜ê¸°"
        >
          <Plus size={20} />
        </button>
      )}

      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ - ê³ ì • ìœ„ì¹˜ */}
      <div className="fixed bottom-32 left-0 right-0 flex justify-center mb-4">
        <AudioRecorder
          onRecordingComplete={(audioUrl) => {
            console.log('ë…¹ìŒëœ ì˜¤ë””ì˜¤ URL:', audioUrl);
            // handleRecordingToggleì—ì„œ ì´ë¯¸ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
          }}
          autoDownload={true}
          fileName="start-recording.wav"
        >
          {({ isRecording, startRecording, stopRecording }) => (
            <RecordControls
              isRecording={isRecording}
              showHelp={showHelp}
              onToggleRecording={async () => {
                await handleRecordingToggle(!isRecording);
                if (isRecording) {
                  stopRecording();
                } else {
                  // AudioRecorderëŠ” ê¶Œí•œì´ ì´ë¯¸ ìˆì„ ë•Œë§Œ ì‹œì‘
                  if (micPermission === 'granted') {
                    startRecording();
                  }
                }
              }}
              onToggleHelp={toggleHelp}
              disabled={!isSupported || micPermission === 'denied'} // ê¶Œí•œ ê±°ë¶€ ì‹œ ë¹„í™œì„±í™”
            />
          )}
        </AudioRecorder>
      </div>

      {/* í•˜ë‹¨ ë„¤ë¹„ê²Œì´ì…˜ ë°” - ê³ ì • ìœ„ì¹˜ */}
      <div className="fixed bottom-0 left-0 right-0 w-full">
        <NavBar />
      </div>
    </div>
  );
};

export default StartRecordView;