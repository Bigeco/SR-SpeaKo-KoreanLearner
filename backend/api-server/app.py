import asyncio
import json
import logging
import numpy as np
from faster_whisper import WhisperModel
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, UploadFile, File
from fastapi.responses import HTMLResponse
import uvicorn

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Korean Speech Recognition API",
    description="Real-time Korean speech recognition using Whisper",
    version="1.0.0"
)

class WhisperService:
    def __init__(self):
        self.model = None
        self.load_model()
    
    def load_model(self):
        """Whisper ëª¨ë¸ ë¡œë“œ (CPU ìµœì í™”)"""
        try:
            logger.info("Loading Whisper model...")
            # CPUì—ì„œ ë¹ ë¥¸ faster-whisper ì‚¬ìš©
            self.model = WhisperModel(
                "tiny",  # tiny, base, small ì¤‘ ì„ íƒ
                device="cpu",
                compute_type="int8",  # CPU ìµœì í™”
                num_workers=1
            )
            logger.info("Whisper model loaded successfully")
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
    
    async def transcribe_audio(self, audio_data: bytes) -> dict:
        """ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            audio_np = np.frombuffer(audio_data, dtype=np.float32)
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ)
            if len(audio_np) < 1600:  # 0.1ì´ˆ ë¯¸ë§Œ
                return {"text": "", "confidence": 0.0}
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì‚¬ ì‹¤í–‰
            result = await asyncio.get_event_loop().run_in_executor(
                None, self._transcribe, audio_np
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Transcription error: {e}")
            return {"text": "", "error": str(e)}
    
    def _transcribe(self, audio_np: np.ndarray) -> dict:
        """ì‹¤ì œ ì „ì‚¬ ì‘ì—… (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        try:
            if self.model and hasattr(self.model, 'transcribe'):
                # faster-whisper ì‚¬ìš©
                segments, info = self.model.transcribe(
                    audio_np,
                    language="ko",
                    vad_filter=True,
                    vad_parameters=dict(min_silence_duration_ms=500)
                )
                
                text = " ".join([segment.text for segment in segments])
                confidence = info.language_probability if hasattr(info, 'language_probability') else 0.9
                
                return {
                    "text": text.strip(),
                    "confidence": confidence,
                    "language": "ko"
                }
            else:
                return {"text": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ", "error": "Model not loaded"}
                
        except Exception as e:
            logger.error(f"Model transcription error: {e}")
            return {"text": "", "error": str(e)}

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
whisper_service = WhisperService()

@app.get("/", response_class=HTMLResponse)
async def root():
    """ê¸°ë³¸ í˜ì´ì§€ - ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return """
    
    
    
        Korean Speech Recognition
        
    
    
        ğŸ¤ Korean Speech Recognition API
        ì‹¤ì‹œê°„ í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.
        
        API ì—”ë“œí¬ì¸íŠ¸:
        
            WebSocket /ws - ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
            POST /transcribe - íŒŒì¼ ì—…ë¡œë“œ ìŒì„± ì¸ì‹
            GET /health - í—¬ìŠ¤ ì²´í¬
        
        
        WebSocket í…ŒìŠ¤íŠ¸:
        
            // ê°„ë‹¨í•œ WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
            function testWebSocket() {
                const ws = new WebSocket(`wss://${window.location.host}/ws`);
                ws.onopen = () => console.log('WebSocket ì—°ê²°ë¨');
                ws.onmessage = (event) => console.log('ë°›ì€ ë©”ì‹œì§€:', event.data);
                ws.onerror = (error) => console.error('WebSocket ì˜¤ë¥˜:', error);
            }
        
        WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
    
    
    """

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹"""
    await websocket.accept()
    logger.info("WebSocket ì—°ê²° ìˆ˜ë½ë¨")
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ 
            data = await websocket.receive_bytes()
            
            # ìŒì„± ì¸ì‹ ì²˜ë¦¬
            result = await whisper_service.transcribe_audio(data)
            
            # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì „ì†¡
            await websocket.send_text(json.dumps(result, ensure_ascii=False))
            
    except WebSocketDisconnect:
        logger.info("WebSocket ì—°ê²° ì¢…ë£Œ")
    except Exception as e:
        logger.error(f"WebSocket ì˜¤ë¥˜: {e}")
        await websocket.close()

@app.post("/transcribe")
async def transcribe_file(file: UploadFile = File(...)):
    """íŒŒì¼ ì—…ë¡œë“œë¥¼ í†µí•œ ìŒì„± ì¸ì‹"""
    try:
        # íŒŒì¼ ë°ì´í„° ì½ê¸°
        audio_data = await file.read()
        
        # ìŒì„± ì¸ì‹ ì²˜ë¦¬
        result = await whisper_service.transcribe_audio(audio_data)
        
        return {
            "filename": file.filename,
            "transcription": result
        }
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì „ì‚¬ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "model": "whisper-base-cpu",
        "language": "korean",
        "version": "1.0.0"
    }